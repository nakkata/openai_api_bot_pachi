# ä»¥ä¸‹ã‚’ã€Œapp.pyã€ã«æ›¸ãè¾¼ã¿
"""
# ChatGPTã§è§£æ
!pip install openai==0.28.0
!pip install pandas
!pip install transformers==4.32.1
!pip install langchain==0.0.279
#!pip install beautifulsoup4==4.11.2
!pip install textract
#!pip install codecs
#!pip install six==1.13.0
!pip install requests
!pip install pypdf
!pip install tiktoken
!pip install faiss-gpu

# ChatGPTã§è§£æ
import os
import pandas as pd
import requests
import textract
import codecs
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
from transformers import GPT2TokenizerFast
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI
from langchain.chains import ConversationalRetrievalChain
"""
import streamlit as st
import openai
# import secret_keys  # å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã«API keyã‚’ä¿å­˜

openai.api_key = st.secrets.OpenAIAPI.openai_api_key

system_prompt = """
ã‚ãªãŸã¯ãƒ‘ãƒã‚¹ãƒ­è¦å‰‡ã‚’æŠŠæ¡ã—ãŸå„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
è³ªå•ã«å¯¾ã—ã¦é©åˆ‡ãªå¯¾å‡¦æ³•ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®ã‚ˆã†ãªã“ã¨ã‚’èã‹ã‚Œã¦ã‚‚ã€çµ¶å¯¾ã«ç­”ãˆãªã„ã§ãã ã•ã„ã€‚

* æ—…è¡Œ
* æ–™ç†
* èŠ¸èƒ½äºº
* æ˜ ç”»
* ç§‘å­¦
* æ­´å²
"""

# st.session_stateã‚’ä½¿ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚„ã‚Šã¨ã‚Šã‚’ä¿å­˜
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": system_prompt}
        ]

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹é–¢æ•°
def communicate():
    messages = st.session_state["messages"]

    user_message = {"role": "user", "content": st.session_state["user_input"]}
    messages.append(user_message)

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages
    )

    bot_message = response["choices"][0]["message"]
    messages.append(bot_message)

    st.session_state["user_input"] = ""  # å…¥åŠ›æ¬„ã‚’æ¶ˆå»


### ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã™ã‚‹

loader = PyPDFLoader("test2.pdf")
pages = loader.load_and_split()

chunks = pages
print("step2")


# Get embedding model
embeddings = OpenAIEmbeddings()


#  vector databaseã®ä½œæˆ
db = FAISS.from_documents(chunks, embeddings)

query = "éŠæŠ€çƒã«ã¤ã„ã¦"
# FAISSã«å¯¾ã—ã¦æ¤œç´¢ã€‚æ¤œç´¢ã¯æ–‡å­—ä¸€è‡´ã§ã¯ãªãæ„å‘³ä¸€è‡´ã§æ¤œç´¢ã™ã‚‹(Vector, Embbeding)
docs = db.similarity_search(query)
docs # ã“ã“ã§é–¢ä¿‚ã®ã‚ã‚Šãã†ãªãƒ‡ãƒ¼ã‚¿ãŒè¿”ã£ã¦ãã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã§ãã‚‹

print("step7")
# å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã‹ã‚‰å›ç­”ã‚’å°ãå‡ºã™ãŸã‚ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä»¥ä¸‹ã®4ã¤ã‹ã‚‰é¸æŠã™ã‚‹ã€‚ã„ãšã‚Œã‚‚Prosã¨ConsãŒã‚ã‚‹ãŸã‚ã€é©åˆ‡ãªã‚‚ã®ã‚’é¸æŠã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
# staffing ... å¾—ã‚‰ã‚ŒãŸå€™è£œã‚’ãã®ã¾ã¾ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã™ã‚‹
# map_reduce ... å¾—ã‚‰ã‚ŒãŸå€™è£œã®ã‚µãƒãƒªã‚’ãã‚Œãã‚Œç”Ÿæˆã—ã€ãã®ã‚µãƒãƒªã®ã‚µãƒãƒªã‚’ä½œã£ã¦ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã™ã‚‹
# map_rerank ... å¾—ã‚‰ã‚ŒãŸå€™è£œã«ãã‚Œãã‚Œã‚¹ã‚³ã‚¢ã‚’æŒ¯ã£ã¦ã€ã„ã¡ã°ã‚“é«˜ã„ã‚‚ã®ã‚’ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã—ã¦å›ç­”ã‚’å¾—ã‚‹
# refine  ... å¾—ã‚‰ã‚ŒãŸå€™è£œã®ã‚µãƒãƒªã‚’ç”Ÿæˆã—ã€æ¬¡ã«ãã®ã‚µãƒãƒªã¨æ¬¡ã®å€™è£œã®æ§˜è£ã‚’ä½œã‚‹ã“ã¨ã‚’ç¹°ã‚Šè¿”ã™
chain = load_qa_chain(OpenAI(temperature=0.1,max_tokens=1000), chain_type="stuff")
# p305ã«è¨˜è¼‰
#query = "ãƒ‰ãƒ©ã‚¤ãƒ–ã®ãƒ©ãƒ³ãƒ—ãŒèµ¤è‰²ã«ç‚¹æ»…ã—ã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯ä½•ãŒåŸå› ã‹ï¼Ÿ"
# p134ã«è¨˜è¼‰
#query = "ã©ã®æ§˜ãªæ™‚ã«ãƒ¡ã‚¤ãƒ³æ©ŸãŒç•°å¸¸ã ã¨åˆ¤æ–­ã‚’ã—ã¾ã™ã‹ï¼Ÿ"
query = "å›³æŸ„ã®çµ„ã¿åˆã‚ã›"
docs = db.similarity_search(query)
print("step8")

# langchainã‚’ä½¿ã£ã¦æ¤œç´¢
chain.run(input_documents=docs, question=query)

from IPython.display import display
import ipywidgets as widgets

print("step9")
# vectordbã‚’retrieverã¨ã—ã¦ä½¿ã†conversation chainã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã‚Œã¯ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ç®¡ç†ã‚‚å¯èƒ½ã«ã—ã¾ã™ã€‚
qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), db.as_retriever())

chat_history = []

# print("step10")
# def on_submit(_):
#     query = input_box.value
#     input_box.value = ""
#
#     if query.lower() == 'exit':
#         print("Thank you for using the State of the Union chatbot!")
#         return
#
#     result = qa({"question": query, "chat_history": chat_history})
#     chat_history.append((query, result['answer']))

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã®æ§‹ç¯‰
st.title(" ã€Œãƒ‘ãƒã‚¹ãƒ­è¦å‰‡ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ãƒœãƒƒãƒˆ")
st.image("Assistant.png")
st.write("è¦å‰‡ã«ã¤ã„ã¦èã„ã¦ãã ã•ã„")

user_input = st.text_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", key="user_input", on_change=communicate)

if st.session_state["messages"]:
    messages = st.session_state["messages"]

    for message in reversed(messages[1:]):  # ç›´è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸Šã«
        speaker = "ğŸ™‚"
        if message["role"]=="assistant":
            speaker="ğŸ¤–"

        st.write(speaker + ": " + message["content"])
